
#Configuration file for Mondo_driver.sh
#   Mondo_driver.sh is meant to run Mondo_chu.sh for all subjects in a group
#   Assumed location of subject raw files: $raw_grp_dir/$subject_id
#   Assumed location of subject output (processed) files: $proc_grp_dir/$subject_id

#---------------Essential path variables-----------------
# directory containing Ref_scripts & Ref_images
    home_dir="/media/mcuser/Partition2/CHU/Production3" 
# dir containing raw subject folders
#   Within the raw subject folders there needs to be either a folder called DICOM
#   that contains the DICOM image or a nifti image file that starts with a 
#   2 and is gzipped (i.e. 2_dti.nii.gz)
    raw_grp_dir="/media/mcuser/HD-QHU3/Chu_data/Test_raw"
# dir to place output subject folders
    proc_grp_dir="/media/mcuser/HD-QHU3/Chu_data/Human_proc/Test_proc/Trash_spoon"
# list of subject names in a group
    subj_list="$raw_grp_dir/U01_subj_list_test.txt"

#----------------------Options---------------------------

# Set to yes to delete existing subject processed directory
    rm_subj_proc_dir="no"

# set to "yes" to run in parallel
#   driver outputs command list and runs in parallel
    run_parallel="no"
#   list of commands to run subjets in parallel
#       will prompt to append or overwrite existing par list
#       my_dir is the location of the Mondo_driver.sh script
        parallel_cmd_list="$home_dir/Parallel_lists/mondo_cmd_list.txt"

# set to "yes" if you are running the pipeline on HiPerGator
#   Warning: Need to test before use
#   Production 3 will not pre-compile matlab scripts like they want us to
    run_HiPerGator="no"
        HiPerGator_config_file=$home_dir/Config_files/HPG_config/HPG_config.txt
        email_status="yes"

# Keep trash folder for troubleshooting
    keep_Trash="yes"
#----------------------------------------------------------

#-------------------- Skip steps -----------------------
# set to "no" to skip dcm2nii, eddy, rotate_bvecs, DTI
    run_preproc="yes"
#       set to "yes" to apply a blur to the data (run_preproc must be set to yes too)
        blur_bool="no"
#       units: mm
            blur_fwhm=3
# set to "no" to skip FW/NODDI Calculation
    run_FWorNODDI="yes"
# set to "no" to skip refitting, resampling, and normalization
    run_postproc="yes"
#       set to "no" to run everything in postproc except normalization
#       (will not run split or suit if normalization is not run)
         run_norm="yes"

# set to "yes" to run SUIT analysis
    run_SUIT="no"

# set to "yes" to run roi analysis or  sliced tract analysis
    run_split="yes"
#   Location of ROI files
#        roi_dir="$home_dir/Ref_images/Rasa_ROIs"
#       ---- AIDP ----
           roi_dir="$home_dir/Ref_images/Parkinsonism_ROIs_and_Tracts_2mm"
#   list of tracts or ROIs, format: <mask_filename>,<x/y/z/n>
#       mask should be in 2mm x 2mm x 2mm resolution
#       xyz describes direction of slicing, n designates to not slice and
#       only average over entire ROI
#        analysis_list="$home_dir/Ref_images/Mask_lists/Rasa_roi_test.txt"
#       ---- AIDP ----
           analysis_list="$home_dir/Ref_images/Mask_lists/AIDP_ROIs_n_Tracts.txt"

# set to "yes" to compile the data from all subjects in this group
#       **** CANNOT RUN COMPILE IN PARALLEL ****
#           Fastest workflow: run everything but split in parallel and then run 
#               split with compile in series
#       This is part of the split script so run_split needs to be "yes" for this to run
    run_compile="yes"
        grp_roi_dir="$proc_grp_dir/Compile_ROI_2"

